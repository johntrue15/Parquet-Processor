name: Test Parquet Data Processor

on:
  workflow_dispatch:
    inputs:
      start_index:
        description: 'Starting index for batch processing'
        required: false
        default: '0'
      total_processed:
        description: 'Total records processed so far'
        required: false
        default: '0'
      batch_size:
        description: 'Number of records to process in each sub-batch'
        required: false
        default: '50'
        type: string
      max_records:
        description: 'Maximum records to process in this workflow run'
        required: false
        default: '50'
        type: string
      segment_name:
        description: 'Name of the segment being processed'
        required: false
        default: 'default'
        type: string
      total_target:
        description: 'Total records to process (0 for all records)'
        required: false
        default: '0'
        type: string

permissions:
  contents: write
  id-token: write
  actions: write

jobs:
  setup:
    uses: ./.github/workflows/setup-environment.yml
    with:
      python-version: "3.10"
      install-chrome: true

  test-process-urls:
    needs: setup
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      # Download the virtual environment
      - name: Download virtual environment
        uses: actions/download-artifact@v4
        with:
          name: venv
          path: |
            ~/.cache/pip
            ~/.local/lib/python3.10/site-packages
          
      - name: Generate Timestamp
        id: timestamp
        run: |
          echo "timestamp=$(date +'%Y-%m-%d_%H-%M-%S')" >> $GITHUB_OUTPUT
          
      - name: Process URLs
        id: process_urls
        run: |
          python .github/scripts/test_parquet_processor.py \
            --output-dir data/processed_parquet/${{ inputs.segment_name }}/${{ steps.timestamp.outputs.timestamp }} \
            --batch-size ${{ inputs.batch_size }} \
            --max-records ${{ inputs.max_records }} \
            --start-index ${{ inputs.start_index }} \
            --total-processed ${{ inputs.total_processed }} \
            --total-target ${{ inputs.total_target }} \
            --log-file data/processed_parquet/${{ inputs.segment_name }}/${{ steps.timestamp.outputs.timestamp }}/processor.log \
            --output-file "${GITHUB_OUTPUT}"
            
      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: processed-parquet-data-${{ inputs.segment_name }}-${{ steps.timestamp.outputs.timestamp }}
          path: |
            data/processed_parquet/${{ inputs.segment_name }}/${{ steps.timestamp.outputs.timestamp }}
            processing_summary.md
          retention-days: 5 
