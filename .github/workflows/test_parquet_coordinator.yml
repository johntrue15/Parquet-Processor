name: Parquet Processing Coordinator

on:
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Records per batch'
        required: false
        default: '100'
        type: string
      segment_size:
        description: 'Records per workflow (e.g. 10000)'
        required: false
        default: '10000'
        type: string
      total_records:
        description: 'Total records to process'
        required: false
        default: '100000'
        type: string

jobs:
  test-run:
    runs-on: ubuntu-latest
    outputs:
      test_success: ${{ steps.evaluate_test.outputs.success }}
      processing_time: ${{ steps.evaluate_test.outputs.avg_time }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Launch Test Workflow
        id: test_workflow
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            console.log('Launching test workflow...');
            
            const testResponse = await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'test_parquet_processor.yml',
              ref: context.ref,
              inputs: {
                start_index: '0',
                total_processed: '0',
                batch_size: '${{ inputs.batch_size }}',
                max_records: '10',  // Process 10 records as test
                segment_name: 'test-run'
              }
            });
            
            // Store the timestamp for checking the run
            const timestamp = new Date().toISOString();
            console.log(`Test workflow launched at ${timestamp}`);
            core.setOutput('launch_time', timestamp);
            
      - name: Wait for Test Workflow
        id: wait_test
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const launchTime = new Date('${{ steps.test_workflow.outputs.launch_time }}');
            let artifactName = '';
            let artifactId = '';
            
            // Wait up to 10 minutes
            for (let i = 0; i < 60; i++) {
              console.log(`Checking test workflow status (attempt ${i + 1}/60)...`);
              
              const runs = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: 'test_parquet_processor.yml',
                status: 'completed',
                branch: context.ref.replace('refs/heads/', ''),
                per_page: 10
              });
              
              // Find the most recent run that matches our test criteria
              const testRun = runs.data.workflow_runs.find(run => {
                const runTime = new Date(run.created_at);
                return runTime >= launchTime && 
                       run.event === 'workflow_dispatch' &&
                       run.head_branch === context.ref.replace('refs/heads/', '') &&
                       run.status === 'completed';
              });
              
              if (testRun) {
                console.log(`Found completed test run: ${testRun.id}`);
                core.setOutput('run_id', testRun.id);
                core.setOutput('conclusion', testRun.conclusion);
                
                // Get artifacts for this run
                const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  run_id: testRun.id
                });
                
                // Find the processed data artifact
                const dataArtifact = artifacts.data.artifacts.find(
                  a => a.name.startsWith('processed-parquet-data-test-run')
                );
                
                if (dataArtifact) {
                  artifactName = dataArtifact.name;
                  artifactId = dataArtifact.id;
                  core.setOutput('artifact_name', artifactName);
                  core.setOutput('artifact_id', artifactId);
                  console.log(`Found artifact: ${artifactName} (ID: ${artifactId})`);
                  break;
                }
              }
              
              // Wait 10 seconds before next check
              if (!testRun) {
                console.log('No matching completed test run found yet, waiting...');
                await new Promise(resolve => setTimeout(resolve, 10000));
              }
            }
      
      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas pyarrow
          
      - name: Download Test Artifacts
        if: steps.wait_test.outputs.conclusion == 'success' && steps.wait_test.outputs.artifact_name != ''
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const path = require('path');
            
            const artifactId = '${{ steps.wait_test.outputs.artifact_id }}';
            const runId = '${{ steps.wait_test.outputs.run_id }}';
            
            console.log(`Downloading artifact from run ${runId}`);
            
            // Download the artifact
            const download = await github.rest.actions.downloadArtifact({
              owner: context.repo.owner,
              repo: context.repo.repo,
              artifact_id: parseInt(artifactId),
              archive_format: 'zip'
            });
            
            // Create artifacts directory
            fs.mkdirSync('test-artifacts', { recursive: true });
            
            // Save the zip file
            const zipPath = path.join('test-artifacts', 'artifact.zip');
            fs.writeFileSync(zipPath, Buffer.from(download.data));
            
            // Extract the zip file
            const AdmZip = require('adm-zip');
            const zip = new AdmZip(zipPath);
            zip.extractAllTo('test-artifacts', true);
            
            // Clean up zip file
            fs.unlinkSync(zipPath);
            
            console.log('Artifact downloaded and extracted');

      - name: Install adm-zip
        if: steps.wait_test.outputs.conclusion == 'success' && steps.wait_test.outputs.artifact_name != ''
        run: npm install adm-zip
      
      - name: Evaluate Test Results
        if: steps.wait_test.outputs.conclusion == 'success'
        id: evaluate_test
        run: |
          python .github/scripts/evaluate_test_run.py \
            --artifacts-dir test-artifacts \
            --github-output $GITHUB_OUTPUT

  coordinate:
    needs: test-run
    if: needs.test-run.outputs.test_success == 'true'
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Calculate Segments
        id: segments
        run: |
          python -c "
          import math
          
          total = int('${{ inputs.total_records }}')
          segment = int('${{ inputs.segment_size }}')
          avg_time = float('${{ needs.test-run.outputs.processing_time }}')
          
          # Adjust segment size based on processing time if needed
          if avg_time > 15:  # If average record takes >15s
              segment = min(segment, 5000)  # Reduce segment size
          
          segments = []
          for i in range(0, total, segment):
              end = min(i + segment, total)
              segments.append({
                  'start': i,
                  'end': end,
                  'name': f'{i//1000}k-{end//1000}k'
              })
          
          # Output segments for next step
          with open('segments.txt', 'w') as f:
              for s in segments:
                  f.write(f'{s[\"start\"]},{s[\"end\"]},{s[\"name\"]}\n')
          
          print(f'Found {len(segments)} segments')
          print(f'Average processing time per record: {avg_time:.2f}s')
          print(f'Adjusted segment size: {segment}')
          "
          
      - name: Trigger Processing Workflows
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const segments = fs.readFileSync('segments.txt', 'utf8')
              .trim()
              .split('\n')
              .map(line => {
                const [start, end, name] = line.split(',');
                return { start, end, name };
              });
            
            console.log(`Launching ${segments.length} processing workflows`);
            
            for (const segment of segments) {
              try {
                await github.rest.actions.createWorkflowDispatch({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: 'test_parquet_processor.yml',
                  ref: context.ref,
                  inputs: {
                    start_index: segment.start,
                    total_processed: '0',
                    batch_size: '${{ inputs.batch_size }}',
                    max_records: (parseInt(segment.end) - parseInt(segment.start)).toString(),
                    segment_name: segment.name
                  }
                });
                console.log(`Launched workflow for segment ${segment.name}`);
                
                // Wait 10 seconds between launches to avoid rate limits
                await new Promise(resolve => setTimeout(resolve, 10000));
              } catch (error) {
                console.error(`Error launching segment ${segment.name}:`, error);
              }
            } 
