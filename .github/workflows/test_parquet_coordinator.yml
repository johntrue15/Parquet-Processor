name: Parquet Processing Coordinator

on:
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Records per batch'
        required: false
        default: '100'
        type: string
      segment_size:
        description: 'Records per workflow (e.g. 10000)'
        required: false
        default: '10000'
        type: string
      total_records:
        description: 'Total records to process'
        required: false
        default: '100000'
        type: string

jobs:
  test-run:
    runs-on: ubuntu-latest
    outputs:
      test_success: ${{ steps.evaluate_test.outputs.success }}
      processing_time: ${{ steps.evaluate_test.outputs.avg_time }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Launch Test Workflow
        id: test_workflow
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            console.log('Launching test workflow...');
            
            const testResponse = await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'test_parquet_processor.yml',
              ref: context.ref,
              inputs: {
                start_index: '0',
                total_processed: '0',
                batch_size: '${{ inputs.batch_size }}',
                max_records: '10',  // Process 10 records as test
                segment_name: 'test-run'
              }
            });
            
            // Store the timestamp for checking the run
            const timestamp = new Date().toISOString();
            console.log(`Test workflow launched at ${timestamp}`);
            core.setOutput('launch_time', timestamp);
            
      - name: Wait for Test Workflow
        id: wait_test
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const launchTime = new Date('${{ steps.test_workflow.outputs.launch_time }}');
            
            // Wait up to 10 minutes
            for (let i = 0; i < 60; i++) {
              console.log(`Checking test workflow status (attempt ${i + 1}/60)...`);
              
              const runs = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: 'test_parquet_processor.yml',
                created: `>=${launchTime.toISOString()}`
              });
              
              if (runs.data.workflow_runs.length > 0) {
                const testRun = runs.data.workflow_runs[0];
                console.log(`Found test run: ${testRun.status}`);
                
                if (testRun.status === 'completed') {
                  console.log('Test workflow completed');
                  core.setOutput('run_id', testRun.id);
                  core.setOutput('conclusion', testRun.conclusion);
                  break;
                }
              }
              
              // Wait 10 seconds before next check
              await new Promise(resolve => setTimeout(resolve, 10000));
            }
      
      - name: Download Test Artifacts
        if: steps.wait_test.outputs.conclusion == 'success'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
              owner: context.repo.owner,
              repo: context.repo.repo,
              run_id: parseInt('${{ steps.wait_test.outputs.run_id }}')
            });
            
            const testArtifact = artifacts.data.artifacts.find(
              a => a.name.startsWith('processed-parquet-data-test-run')
            );
            
            if (testArtifact) {
              console.log(`Found test artifact: ${testArtifact.name}`);
              core.setOutput('artifact_id', testArtifact.id);
            } else {
              core.setFailed('No test artifacts found');
            }
      
      - name: Evaluate Test Results
        if: steps.wait_test.outputs.conclusion == 'success'
        id: evaluate_test
        run: |
          python -c "
          import pandas as pd
          import glob
          import os
          
          success = False
          avg_time = 0
          
          try:
              test_files = glob.glob('processed-parquet-data-test-run*/*.parquet')
              if test_files:
                  df = pd.read_parquet(test_files[0])
                  records = len(df)
                  avg_time = df.processing_time.mean()
                  errors = df['error'].notna().sum()
                  
                  print(f'Test Results:')
                  print(f'Records processed: {records}')
                  print(f'Average processing time: {avg_time:.2f}s')
                  print(f'Records with errors: {errors}')
                  
                  # Consider test successful if:
                  # 1. At least 8 records processed (out of 10)
                  # 2. Average processing time < 30 seconds
                  # 3. Error rate < 20%
                  success = (records >= 8 and 
                           avg_time < 30 and 
                           errors/records < 0.2)
                  
              print(f'Test evaluation: {"SUCCESS" if success else "FAILED"}')
              
              # Set outputs for next job
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write(f'success={str(success).lower()}\n')
                  f.write(f'avg_time={avg_time}\n')
                  
          except Exception as e:
              print(f'Error evaluating test: {e}')
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write('success=false\n')
                  f.write('avg_time=0\n')
          "

  coordinate:
    needs: test-run
    if: needs.test-run.outputs.test_success == 'true'
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Calculate Segments
        id: segments
        run: |
          python -c "
          import math
          
          total = int('${{ inputs.total_records }}')
          segment = int('${{ inputs.segment_size }}')
          avg_time = float('${{ needs.test-run.outputs.processing_time }}')
          
          # Adjust segment size based on processing time if needed
          if avg_time > 15:  # If average record takes >15s
              segment = min(segment, 5000)  # Reduce segment size
          
          segments = []
          for i in range(0, total, segment):
              end = min(i + segment, total)
              segments.append({
                  'start': i,
                  'end': end,
                  'name': f'{i//1000}k-{end//1000}k'
              })
          
          # Output segments for next step
          with open('segments.txt', 'w') as f:
              for s in segments:
                  f.write(f'{s[\"start\"]},{s[\"end\"]},{s[\"name\"]}\n')
          
          print(f'Found {len(segments)} segments')
          print(f'Average processing time per record: {avg_time:.2f}s')
          print(f'Adjusted segment size: {segment}')
          "
          
      - name: Trigger Processing Workflows
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const segments = fs.readFileSync('segments.txt', 'utf8')
              .trim()
              .split('\n')
              .map(line => {
                const [start, end, name] = line.split(',');
                return { start, end, name };
              });
            
            console.log(`Launching ${segments.length} processing workflows`);
            
            for (const segment of segments) {
              try {
                await github.rest.actions.createWorkflowDispatch({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: 'test_parquet_processor.yml',
                  ref: context.ref,
                  inputs: {
                    start_index: segment.start,
                    total_processed: '0',
                    batch_size: '${{ inputs.batch_size }}',
                    max_records: (parseInt(segment.end) - parseInt(segment.start)).toString(),
                    segment_name: segment.name
                  }
                });
                console.log(`Launched workflow for segment ${segment.name}`);
                
                // Wait 10 seconds between launches to avoid rate limits
                await new Promise(resolve => setTimeout(resolve, 10000));
              } catch (error) {
                console.error(`Error launching segment ${segment.name}:`, error);
              }
            } 
