name: Parquet Processing Coordinator

on:
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Records per batch'
        required: false
        default: '100'
        type: string
      segment_size:
        description: 'Records per workflow (e.g. 10000)'
        required: false
        default: '10000'
        type: string
      total_records:
        description: 'Total records to process'
        required: false
        default: '100000'
        type: string
      max_concurrent:
        description: 'Maximum concurrent workflows'
        required: false
        default: '5'
        type: string

# Add concurrency to prevent multiple coordinators running simultaneously
concurrency:
  group: parquet_coordinator
  cancel-in-progress: false

permissions:
  contents: read
  actions: write
  id-token: write

jobs:
  test-run:
    runs-on: ubuntu-latest
    timeout-minutes: 15  # Add timeout for the test run
    outputs:
      test_success: ${{ steps.evaluate_test.outputs.success }}
      processing_time: ${{ steps.evaluate_test.outputs.avg_time }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Launch Test Workflow
        id: test_workflow
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            console.log('Launching test workflow...');
            
            const testResponse = await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'test_parquet_processor.yml',
              ref: context.ref,
              inputs: {
                start_index: '0',
                total_processed: '0',
                batch_size: '${{ inputs.batch_size }}',
                max_records: '10',  // Process 10 records as test
                segment_name: 'test-run'
              }
            });
            
            // Store the timestamp for checking the run
            const timestamp = new Date().toISOString();
            console.log(`Test workflow launched at ${timestamp}`);
            core.setOutput('launch_time', timestamp);
            
      - name: Wait for Test Workflow
        id: wait_test
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const launchTime = new Date('${{ steps.test_workflow.outputs.launch_time }}');
            let artifactName = '';
            let artifactId = '';
            let timedOut = true;
            
            console.log(`Looking for workflows launched after ${launchTime.toISOString()}`);
            
            // Wait up to 10 minutes
            for (let i = 0; i < 60; i++) {
              console.log(`Checking test workflow status (attempt ${i + 1}/60)...`);
              
              try {
                const runs = await github.rest.actions.listWorkflowRuns({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: 'test_parquet_processor.yml',
                  status: 'completed',
                  branch: context.ref.replace('refs/heads/', ''),
                  per_page: 10
                });
                
                console.log(`Found ${runs.data.workflow_runs.length} recent workflow runs`);
                
                // Find the most recent run that matches our test criteria
                const testRun = runs.data.workflow_runs.find(run => {
                  const runTime = new Date(run.created_at);
                  const matches = runTime >= launchTime && 
                         run.event === 'workflow_dispatch' &&
                         run.head_branch === context.ref.replace('refs/heads/', '') &&
                         run.status === 'completed';
                  
                  if (matches) {
                    console.log(`Found matching run: ${run.id} (created: ${run.created_at}, conclusion: ${run.conclusion})`);
                  }
                  return matches;
                });
                
                if (testRun) {
                  console.log(`Found completed test run: ${testRun.id}`);
                  if (testRun.conclusion !== 'success') {
                    core.setFailed(`Test workflow failed with conclusion: ${testRun.conclusion}`);
                    break;
                  }
                  
                  core.setOutput('run_id', testRun.id);
                  core.setOutput('conclusion', testRun.conclusion);
                  
                  // Get artifacts for this run
                  const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    run_id: testRun.id
                  });
                  
                  console.log(`Found ${artifacts.data.artifacts.length} artifacts for run ${testRun.id}`);
                  
                  // Find the processed data artifact
                  const dataArtifact = artifacts.data.artifacts.find(
                    a => a.name.startsWith('processed-parquet-data-test-run')
                  );
                  
                  if (dataArtifact) {
                    artifactName = dataArtifact.name;
                    artifactId = dataArtifact.id;
                    core.setOutput('artifact_name', artifactName);
                    core.setOutput('artifact_id', artifactId);
                    console.log(`Found artifact: ${artifactName} (ID: ${artifactId})`);
                    timedOut = false;
                    break;
                  } else {
                    console.log('No matching artifacts found. Available artifacts:', 
                      artifacts.data.artifacts.map(a => a.name).join(', '));
                  }
                }
              } catch (error) {
                console.error('Error checking workflow status:', error);
              }
              
              // Wait 10 seconds before next check
              if (timedOut) {
                console.log('No matching completed test run found yet, waiting...');
                await new Promise(resolve => setTimeout(resolve, 10000));
              }
            }
            
            if (timedOut) {
              core.setFailed('Timed out waiting for test workflow to complete');
            }
      
      - uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas pyarrow
          npm install adm-zip
          
      - name: Download and Extract Test Artifacts
        if: steps.wait_test.outputs.conclusion == 'success' && steps.wait_test.outputs.artifact_name != ''
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const path = require('path');
            const AdmZip = require(path.join(process.env.GITHUB_WORKSPACE, 'node_modules/adm-zip'));
            
            const artifactId = '${{ steps.wait_test.outputs.artifact_id }}';
            const runId = '${{ steps.wait_test.outputs.run_id }}';
            
            console.log(`Downloading artifact from run ${runId}`);
            
            try {
              // Download the artifact
              const download = await github.rest.actions.downloadArtifact({
                owner: context.repo.owner,
                repo: context.repo.repo,
                artifact_id: parseInt(artifactId),
                archive_format: 'zip'
              });
              
              // Create artifacts directory
              const artifactsDir = 'test-artifacts';
              fs.mkdirSync(artifactsDir, { recursive: true });
              
              // Save the zip file
              const zipPath = path.join(artifactsDir, 'artifact.zip');
              fs.writeFileSync(zipPath, Buffer.from(download.data));
              
              // Extract the zip file
              const zip = new AdmZip(zipPath);
              
              // List contents before extraction
              const entries = zip.getEntries();
              console.log('Zip contents:', entries.map(e => e.entryName));
              
              // Extract to artifacts directory
              zip.extractAllTo(artifactsDir, true);
              
              // Clean up zip file
              fs.unlinkSync(zipPath);
              
              // List extracted contents
              const files = fs.readdirSync(artifactsDir, { recursive: true });
              console.log('Extracted contents:', files);
              
              console.log('Artifact downloaded and extracted successfully');
            } catch (error) {
              console.error('Error downloading or extracting artifact:', error);
              core.setFailed(error.message);
            }

      - name: Evaluate Test Results
        if: steps.wait_test.outputs.conclusion == 'success'
        id: evaluate_test
        run: |
          python .github/scripts/evaluate_test_run.py \
            --artifacts-dir test-artifacts \
            --github-output $GITHUB_OUTPUT

  coordinate:
    needs: test-run
    if: needs.test-run.outputs.test_success == 'true'
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Calculate Segments
        id: segments
        run: |
          python -c "
          import math
          
          total = int('${{ inputs.total_records }}')
          segment = int('${{ inputs.segment_size }}')
          avg_time = float('${{ needs.test-run.outputs.processing_time }}')
          
          # Adjust segment size based on processing time if needed
          if avg_time > 15:  # If average record takes >15s
              segment = min(segment, 5000)  # Reduce segment size
          
          segments = []
          for i in range(0, total, segment):
              end = min(i + segment, total)
              segments.append({
                  'start': i,
                  'end': end,
                  'name': f'{i//1000}k-{end//1000}k'
              })
          
          # Output segments for next step
          with open('segments.txt', 'w') as f:
              for s in segments:
                  f.write(f'{s[\"start\"]},{s[\"end\"]},{s[\"name\"]}\n')
          
          print(f'Found {len(segments)} segments')
          print(f'Average processing time per record: {avg_time:.2f}s')
          print(f'Adjusted segment size: {segment}')
          "
          
      - name: Trigger Processing Workflows
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const MAX_CONCURRENT = parseInt('${{ inputs.max_concurrent }}');
            const BATCH_SIZE = 3; // Number of workflows to launch at once
            const BATCH_DELAY = 30000; // 30 seconds between batches
            
            const segments = fs.readFileSync('segments.txt', 'utf8')
              .trim()
              .split('\n')
              .map(line => {
                const [start, end, name] = line.split(',');
                return { start, end, name };
              });
            
            console.log(`Launching ${segments.length} processing workflows`);
            
            // Process segments in batches
            for (let i = 0; i < segments.length; i += BATCH_SIZE) {
              const batch = segments.slice(i, i + BATCH_SIZE);
              console.log(`Processing batch ${i/BATCH_SIZE + 1} of ${Math.ceil(segments.length/BATCH_SIZE)}`);
              
              // Check current running workflows
              const running = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: 'test_parquet_processor.yml',
                status: 'in_progress'
              });
              
              // Wait if too many workflows are running
              while (running.data.total_count >= MAX_CONCURRENT) {
                console.log(`${running.data.total_count} workflows running, waiting...`);
                await new Promise(resolve => setTimeout(resolve, 30000));
                running = await github.rest.actions.listWorkflowRuns({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: 'test_parquet_processor.yml',
                  status: 'in_progress'
                });
              }
              
              // Launch workflows in this batch
              for (const segment of batch) {
                try {
                  await github.rest.actions.createWorkflowDispatch({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    workflow_id: 'test_parquet_processor.yml',
                    ref: context.ref,
                    inputs: {
                      start_index: segment.start,
                      total_processed: '0',
                      batch_size: '${{ inputs.batch_size }}',
                      max_records: (parseInt(segment.end) - parseInt(segment.start)).toString(),
                      segment_name: segment.name,
                      total_target: '${{ inputs.total_records }}'
                    }
                  });
                  console.log(`Launched workflow for segment ${segment.name}`);
                  
                  // Small delay between individual launches
                  await new Promise(resolve => setTimeout(resolve, 5000));
                } catch (error) {
                  console.error(`Error launching segment ${segment.name}:`, error);
                  core.setFailed(`Failed to launch segment ${segment.name}: ${error.message}`);
                }
              }
              
              // Wait between batches
              if (i + BATCH_SIZE < segments.length) {
                console.log(`Waiting ${BATCH_DELAY/1000} seconds before next batch...`);
                await new Promise(resolve => setTimeout(resolve, BATCH_DELAY));
              }
            } 
